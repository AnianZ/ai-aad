{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase2 - RAG\n",
    "\n",
    "If not already done run this in the top level folder:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import openai\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_false = \"true_false\"\n",
    "    popular_choice = \"popular_choice\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom data\n",
    "Here's how you load custom data into an embedding model and how you use langchain to query it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.document_loaders import DirectoryLoader, UnstructuredMarkdownLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import os\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "\n",
    "# use an embeddingsmodel to create embeddings\n",
    "embeddings_model = AzureOpenAIEmbeddings(    \n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version = os.getenv(\"OPENAI_EMBEDDING_API_VERSION\"),\n",
    "    model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    ")\n",
    "\n",
    "AZURE_OPENAI_VERSION=\"2024-02-01\"\n",
    "# Create an instance of Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "    api_version=AZURE_OPENAI_VERSION\n",
    ")\n",
    "\n",
    "# load your data\n",
    "data_dir = \"data/movies\"\n",
    "documents = DirectoryLoader(path=data_dir, glob=\"*.md\", show_progress=True, loader_cls=UnstructuredMarkdownLoader).load()\n",
    "\n",
    "#create chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "document_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# create a qdrant index in memory\n",
    "qdrant = Qdrant.from_documents(\n",
    "    document_chunks,\n",
    "    embeddings_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"movies\",\n",
    ")\n",
    "\n",
    "# create a retriever to allow a rag flow\n",
    "retriever = qdrant.as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "loader = DirectoryLoader(path=data_dir, glob=\"*.md\", show_progress=True, loader_cls=UnstructuredMarkdownLoader)\n",
    "\n",
    "index = VectorstoreIndexCreator(embedding=embeddings_model).from_loaders([loader])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me about the latest Ant Man movie. When was it released? What is it about?\"\n",
    "index.query(llm=llm, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR Mission: \n",
    "Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service. \n",
    "Ensure the answers provided are correct and in the correct format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    \"\"\"\n",
    "    Ask a question\n",
    "    \"\"\"\n",
    "    answer = index.query(llm=llm, question=ask.question)\n",
    "    \n",
    "    print(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ask = Ask(question=\"Tell me about the latest Ant Man movie. When was it released? \", type=QuestionType.estimation)\n",
    "answer = await ask_question(ask)\n",
    "print('Answer:', answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase2 $AZURE_ENV_NAME\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

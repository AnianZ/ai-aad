{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase2 - RAG\n",
    "\n",
    "If not already done run this in the top level folder:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://cog-fkplarx5db7we.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import openai\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_false = \"true_false\"\n",
    "    popular_choice = \"popular_choice\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom data\n",
    "Here's how you load custom data into an embedding model and how you use langchain to query it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 131.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest Ant-Man movie, \"Ant-Man and the Smorgs: Smorgmania,\" was released on February 15, 2026. It is an action-adventure science fiction film, featuring superhero partners Smorg Smorisson, Smorg McLean, and Jenny Smorgth. In this movie, they explore the Smorgs Realm and encounter strange new Smorgs, embarking on an adventurous journey that pushes their limits. The movie has gained popularity with an average vote of 9.5.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, UnstructuredMarkdownLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "\n",
    "# use an embeddingsmodel to create embeddings\n",
    "embeddings_model = AzureOpenAIEmbeddings(    \n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version = os.getenv(\"OPENAI_EMBEDDING_API_VERSION\"),\n",
    "    model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    ")\n",
    "\n",
    "AZURE_OPENAI_VERSION=\"2024-02-01\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "# 1. load data into qdrant db in aca or locally\n",
    "# load your data\n",
    "data_dir = \"data/movies\"\n",
    "documents = DirectoryLoader(path=data_dir, glob=\"*.md\", show_progress=True, loader_cls=UnstructuredMarkdownLoader).load()\n",
    "\n",
    "# use local quadrant (for debugging)\n",
    "qdrant = Qdrant.from_documents(\n",
    "    documents,\n",
    "    embeddings_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"movies\",\n",
    ")\n",
    "\n",
    "# use quadrant in aca\n",
    "# # --> aus Env, URL von Quadrant\n",
    "# url = \"http://localhost:6333\"\n",
    "# qdrant = Qdrant.from_documents(documents,embeddings_model,url=url,prefer_grpc=False,collection_name=\"my_movies\",)\n",
    "\n",
    "\n",
    "# 2. find relevant chunks from vector db\n",
    "question = \"Tell me about the latest Ant Man movie. When was it released?\"\n",
    "found_docs = qdrant.similarity_search(question)\n",
    "found_docs_as_text = \" \"\n",
    "for elem in enumerate(found_docs, start=1):    \n",
    "    found_docs_as_text += \" \"+ elem[1].page_content\n",
    "\n",
    "# 3. ask llm based on releveant chunks\n",
    "system_prompt = \"You are an assistant to the user, you are given some context below, please answer the query of the user with as detail as possible\"\n",
    "\n",
    "parameters = [system_prompt, ' Context:', found_docs_as_text , ' Question:', question]\n",
    "joined_parameters = ''.join(parameters)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : joined_parameters}],\n",
    "    )\n",
    "\n",
    "print (response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR Mission: \n",
    "Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service. \n",
    "Ensure the answers provided are correct and in the correct format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    \"\"\"\n",
    "    Ask a question\n",
    "    \"\"\"\n",
    "    #####\n",
    "    # implement rag flow here\n",
    "    ######\n",
    "    \n",
    "    print(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ask = Ask(question=\"Tell me about the latest Ant Man movie. When was it released? \", type=QuestionType.estimation)\n",
    "answer = await ask_question(ask)\n",
    "print('Answer:', answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase2 $AZURE_ENV_NAME\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not already done run this in the top level folder:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://cog-fkplarx5db7we.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import openai\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if stuff works in general, you can run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.chat.completions.create(\n",
    "#     model = model_name,    \n",
    "#     messages = [{\"role\" : \"assistant\", \"content\" : \"The one thing I love more than anything else is \"}],\n",
    "# )\n",
    "\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_false = \"true_false\"\n",
    "    popular_choice = \"popular_choice\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def ask_question(ask: Ask):\n",
    "#     \"\"\"\n",
    "#     Ask a question\n",
    "#     \"\"\"\n",
    "#     print('Sending a request to openai')\n",
    "\n",
    "#     # Send a completion call to generate an answer\n",
    "#     print('Sending a request to openai --')\n",
    "\n",
    "#     start_phrase = ask.question\n",
    "#     if(ask.type == QuestionType.multiple_choice):\n",
    "#         response = client.chat.completions.create(\n",
    "#         model = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "#         messages = [{\"role\" : \"assistant\", \"content\" : start_phrase}, \n",
    "#                     { \"role\" : \"system\", \"content\" : \"answer with the character or number of the right option only . For example: Question: Which of the following is  a color? a. Tree b. Flower c. Green  Answer: c \"}]\n",
    "          \n",
    "#     )\n",
    "        \n",
    "#     if(ask.type == QuestionType.true_false):\n",
    "#         response = client.chat.completions.create(\n",
    "#         model = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "#         messages = [{\"role\" : \"assistant\", \"content\" : start_phrase}, \n",
    "#                 { \"role\" : \"system\", \"content\" : \"respond with true or false only. \"}]\n",
    "      \n",
    "#     )\n",
    "\n",
    "#     print(response.choices[0].message.content)\n",
    "        \n",
    "#     answer = Answer(answer=response.choices[0].message.content)\n",
    "#     answer.correlationToken = ask.correlationToken\n",
    "#     answer.promptTokensUsed = response.usage.prompt_tokens\n",
    "#     answer.completionTokensUsed = response.usage.completion_tokens\n",
    "\n",
    "#     print('Answer:', answer)\n",
    "#     return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR Mission: Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    \"\"\"\n",
    "    Ask a question\n",
    "    \"\"\"\n",
    "\n",
    "    # Send a completion call to generate an answer\n",
    "    print('Sending a request to openai')\n",
    "    start_phrase = ask.question\n",
    "    response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : start_phrase}],\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    print(response)\n",
    "    answer = Answer(answer=response.choices[0].message.content)\n",
    "    answer.correlationToken = ask.correlationToken\n",
    "    answer.promptTokensUsed = response.usage.prompt_tokens\n",
    "    answer.completionTokensUsed = response.usage.completion_tokens\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending a request to openai\n",
      "c. Green\n",
      "ChatCompletion(id='chatcmpl-9RZul43FC7lg1qVPjwLCU357OEQYY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='c. Green', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1716359939, model='gpt-35-turbo', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=3, prompt_tokens=24, total_tokens=27), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "Answer: answer='c. Green' correlationToken=None promptTokensUsed=24 completionTokensUsed=3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ask = Ask(question=\"Which of the following is a color? a. Tree b. Flower c. Green\", type=QuestionType.multiple_choice)\n",
    "answer = await ask_question(ask)\n",
    "print('Answer:', answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase1 $AZURE_ENV_NAME\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
